{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO-4604 HW5: Ensemble Learning \n",
    "\n",
    "* Created by Michael Paul on November 27, 2017\n",
    "* Modified by James Gallmeister on December 3, 2017\n",
    "\n",
    "##### Deadline: Monday, December 4, 8:00pm MT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will continue working with the Twitter sentiment dataset from HW4. This time, you will build a classifier that combines the individual classifiers submitted by everyone in the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to hand in\n",
    "\n",
    "You will submit the assignment on Piazza. A private note to the instructor should be submitted with the subject _\"Submission 5 from [your full name]\"_ with the submission file(s) as an attachment. The note should be submitted to the `submissions` folder (**not** the `hw5` folder).\n",
    "\n",
    "Submit a single Jupyter notebook named `hw5lastname.ipynb`, where lastname is replaced with your last name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Dataset\n",
    "\n",
    "Recall that in HW4B, you submitted the sentiment probabilities from your classifier. The features were randomized so that most classifiers will be slightly different.\n",
    "\n",
    "The probabilities from all of the submissions have been put together for this assignment. The format is a CSV file where the first column is the label, and subsequent columns are classifier probabilities. Each three-column sequence is the probability of negative ($-1$), neutral ($0$), and positive ($1$), in that order. For example, column 2 (where column 1 is the label) is the negative probability from the first submission, column 4 is the positive probability of the first submission, column 5 is the negative probability of the second submission, column 6 is the neutral probability of the second submission, and so on. There are two files: the first should be used for training and cross-validation, and the second should be used for testing.\n",
    "\n",
    "As usual, run the code below to load the data. The accuracies of each individual system are also calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission 1:\n",
      " Validation accuracy: 0.651113\n",
      " Test accuracy: 0.633333\n",
      "Submission 2:\n",
      " Validation accuracy: 0.616119\n",
      " Test accuracy: 0.600000\n",
      "Submission 3:\n",
      " Validation accuracy: 0.716861\n",
      " Test accuracy: 0.755556\n",
      "Submission 4:\n",
      " Validation accuracy: 0.752916\n",
      " Test accuracy: 0.766667\n",
      "Submission 5:\n",
      " Validation accuracy: 0.722163\n",
      " Test accuracy: 0.744444\n",
      "Submission 6:\n",
      " Validation accuracy: 0.727466\n",
      " Test accuracy: 0.766667\n",
      "Submission 7:\n",
      " Validation accuracy: 0.737010\n",
      " Test accuracy: 0.755556\n",
      "Submission 8:\n",
      " Validation accuracy: 0.760339\n",
      " Test accuracy: 0.788889\n",
      "Submission 9:\n",
      " Validation accuracy: 0.727466\n",
      " Test accuracy: 0.777778\n",
      "Submission 10:\n",
      " Validation accuracy: 0.645811\n",
      " Test accuracy: 0.644444\n",
      "Submission 11:\n",
      " Validation accuracy: 0.679745\n",
      " Test accuracy: 0.600000\n",
      "Submission 12:\n",
      " Validation accuracy: 0.734889\n",
      " Test accuracy: 0.766667\n",
      "Submission 13:\n",
      " Validation accuracy: 0.621421\n",
      " Test accuracy: 0.633333\n",
      "Submission 14:\n",
      " Validation accuracy: 0.713680\n",
      " Test accuracy: 0.744444\n",
      "Submission 15:\n",
      " Validation accuracy: 0.721103\n",
      " Test accuracy: 0.744444\n",
      "Submission 16:\n",
      " Validation accuracy: 0.694592\n",
      " Test accuracy: 0.733333\n",
      "Submission 17:\n",
      " Validation accuracy: 0.724284\n",
      " Test accuracy: 0.755556\n",
      "Submission 18:\n",
      " Validation accuracy: 0.768823\n",
      " Test accuracy: 0.733333\n",
      "Submission 19:\n",
      " Validation accuracy: 0.728526\n",
      " Test accuracy: 0.755556\n",
      "Submission 20:\n",
      " Validation accuracy: 0.648993\n",
      " Test accuracy: 0.611111\n",
      "Submission 21:\n",
      " Validation accuracy: 0.714740\n",
      " Test accuracy: 0.755556\n",
      "Submission 22:\n",
      " Validation accuracy: 0.769883\n",
      " Test accuracy: 0.766667\n",
      "Submission 23:\n",
      " Validation accuracy: 0.720042\n",
      " Test accuracy: 0.733333\n",
      "Submission 24:\n",
      " Validation accuracy: 0.730647\n",
      " Test accuracy: 0.777778\n",
      "Submission 25:\n",
      " Validation accuracy: 0.753977\n",
      " Test accuracy: 0.788889\n",
      "Submission 26:\n",
      " Validation accuracy: 0.645811\n",
      " Test accuracy: 0.644444\n",
      "Submission 27:\n",
      " Validation accuracy: 0.748674\n",
      " Test accuracy: 0.755556\n",
      "Submission 28:\n",
      " Validation accuracy: 0.686108\n",
      " Test accuracy: 0.733333\n",
      "Submission 29:\n",
      " Validation accuracy: 0.688229\n",
      " Test accuracy: 0.600000\n",
      "Submission 30:\n",
      " Validation accuracy: 0.747614\n",
      " Test accuracy: 0.777778\n",
      "Submission 31:\n",
      " Validation accuracy: 0.747614\n",
      " Test accuracy: 0.755556\n",
      "Submission 32:\n",
      " Validation accuracy: 0.741251\n",
      " Test accuracy: 0.755556\n",
      "Submission 33:\n",
      " Validation accuracy: 0.728526\n",
      " Test accuracy: 0.755556\n",
      "Submission 34:\n",
      " Validation accuracy: 0.713680\n",
      " Test accuracy: 0.744444\n",
      "Submission 35:\n",
      " Validation accuracy: 0.721103\n",
      " Test accuracy: 0.744444\n",
      "Submission 36:\n",
      " Validation accuracy: 0.728526\n",
      " Test accuracy: 0.755556\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_train = pd.read_csv('http://cmci.colorado.edu/classes/INFO-4604/data/tweet_predictions_cv.csv', header=None)\n",
    "df_test = pd.read_csv('http://cmci.colorado.edu/classes/INFO-4604/data/tweet_predictions_test.csv', header=None)\n",
    "\n",
    "Y_train = df_train.iloc[0:, 0].values\n",
    "X_train = df_train.iloc[0:, 1:].values\n",
    "\n",
    "Y_test = df_test.iloc[0:, 0].values\n",
    "X_test = df_test.iloc[0:, 1:].values\n",
    "\n",
    "for i in np.arange(0, len(X_train[0]), 3):\n",
    "    print(\"Submission %d:\" % (1 + int(i/3)))\n",
    "    predictions_cv = [np.argmax(x)-1 for x in X_train[0:, i:i+3]]\n",
    "    print(\" Validation accuracy: %0.6f\" % accuracy_score(Y_train, predictions_cv))\n",
    "    predictions_test = [np.argmax(x)-1 for x in X_test[0:, i:i+3]]\n",
    "    print(\" Test accuracy: %0.6f\" % accuracy_score(Y_test, predictions_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Ensemble Classifier [7 points]\n",
    "\n",
    "First, build a classifier that uses the probabilities from the 36 submissions as features. Since each submission contains 3 probabilities, there are 108 total features.\n",
    "\n",
    "Following HW4B, you should use multinomial logistic regression as the classifier. Use `sklearn`'s [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) class, setting the `multi_class` argument to `'multinomial'`, the `solver` argument to `'lbfgs'`, and the `random_state` argument to `123` (as usual). \n",
    "\n",
    "Additionally, use [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to select the `C` parameter using 5-fold cross-validation. For the grid search, try the following values for `C`: ${0.1, 0.2, 0.3, 0.4, \\ldots, 1.8, 1.9, 2.0}$. (You can easily generate this list of values using [`numpy.arange`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.arange.html).) When making predictions on the test data, you should use the optimal classifier tuned during cross-validation.\n",
    "\n",
    "You may wish to refer to the HW4B code to get started, since the code will be similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 1.1: Implement the ensemble classifier as described, and calculate both the cross-validation accuracy and test accuracy.\n",
    "\n",
    "See below output.\n",
    "\n",
    "#### Deliverable 1.2: Examine the validation and test accuracies of the individual submissions above. How do these accuracies compare to the validation and test accuracy of your ensemble classifier?\n",
    "\n",
    "The validation and test accuracy of my ensemble classifier is much higher than that of the individual submissions above.\n",
    "\n",
    "#### Deliverable 1.3: Based on what was discussed in lecture, explain these results. If the ensemble outperformed the individual classifiers, explain why ensembles are able to do this. If the ensemble did not outperform the individual classifiers, explain why this particular ensemble might not have been effective.\n",
    "\n",
    "The ensemble outperformed the individual classifiers. This may be because, as an ensemble, it averages out biases learned by the different individual classifiers, it reduces the variance of the individual classifiers and it is unlikely to overfit if none of the individual models overfit. It doesn't seem like any of the individual models were overfitting based on the individual model results above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best parameter settings:', {'C': 0.40000000000000002})\n",
      "Validation accuracy: 0.815483\n",
      "Test accuracy: 0.800000\n"
     ]
    }
   ],
   "source": [
    "# code for 1.1 here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "base_classifier = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', random_state = 123)\n",
    "params = [{'C': np.arange(0.1,2.0, 0.1)}]\n",
    "\n",
    "gs_classifier = GridSearchCV(base_classifier, params, cv=5)\n",
    "gs_classifier.fit(X_train, Y_train)\n",
    "print('Best parameter settings:', gs_classifier.best_params_)\n",
    "print('Validation accuracy: %0.6f' % gs_classifier.best_score_)\n",
    "print('Test accuracy: %0.6f' % gs_classifier.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Dimensionality Reduction [5 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the features are continuous-valued and correlated with each other, this feature set is a good candidate for dimensionality reduction with principal component analysis (PCA). You will experiment with PCA here.\n",
    "\n",
    "Use the [`sklearn.decomposition.PCA`](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) class to transform the feature vectors (`X_train` and `X_test`) using PCA.  You should fit PCA with the training data, and then transform the feature vectors of both the training and test data. This will require a combination of the `fit`, `transform`, and/or `fit_transform` functions. Read the documentation linked here. This class is similar to the [`sklearn.feature_selection.chi2`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html) class that you used in HW4B, so you may find it helpful to refer back to your code for feature selection.\n",
    "\n",
    "When creating a `PCA` object, you set the number of components (that is, the dimensionality of the feature vectors) with the `n_components` argument. Additionally, set `random_state` to `123`.\n",
    "\n",
    "You should run the same classifier from Problem 1 on the PCA-reduced data. You should continue to use `GridSearchCV` to tune `C`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deliverable 2.1: Apply PCA to the data and calculate the validation and test accuracies when the number of components is each of: $1, 2, 10, 20, 30, 40, 50, 100$.\n",
    "\n",
    "[you may wish to plot these results, but it is not required as long as your results are readable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy with 1 components: 0.667020\n",
      "Test Accuracy with 1 components: 0.677778\n",
      "Validation Accuracy with 2 components: 0.763521\n",
      "Test Accuracy with 2 components: 0.777778\n",
      "Validation Accuracy with 10 components: 0.779427\n",
      "Test Accuracy with 10 components: 0.788889\n",
      "Validation Accuracy with 20 components: 0.797455\n",
      "Test Accuracy with 20 components: 0.800000\n",
      "Validation Accuracy with 30 components: 0.808059\n",
      "Test Accuracy with 30 components: 0.822222\n",
      "Validation Accuracy with 40 components: 0.814422\n",
      "Test Accuracy with 40 components: 0.811111\n",
      "Validation Accuracy with 50 components: 0.814422\n",
      "Test Accuracy with 50 components: 0.777778\n",
      "Validation Accuracy with 100 components: 0.814422\n",
      "Test Accuracy with 100 components: 0.800000\n"
     ]
    }
   ],
   "source": [
    "# code for 2.1 here\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "comp = [1,2,10,20,30,40,50,100]\n",
    "base_classifier1 = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', random_state = 123)\n",
    "params = [{'C': np.arange(0.1,2.0, 0.1)}]\n",
    "gs_classifier1 = GridSearchCV(base_classifier1, params, cv=5)\n",
    "\n",
    "for x in range(8):\n",
    "    pca = PCA(n_components = comp[x], random_state=123)\n",
    "    pca.fit(X_train)\n",
    "    pca_x_train = pca.transform(X_train)\n",
    "    pca_x_test = pca.transform(X_test)\n",
    "    gs_classifier1.fit(pca_x_train, Y_train)\n",
    "    print('Validation Accuracy with %d components: %0.6f' % (comp[x], gs_classifier1.best_score_))\n",
    "    print('Test Accuracy with %d components: %0.6f' % (comp[x], gs_classifier1.score(pca_x_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Feedback [+1 EC]\n",
    "\n",
    "#### Deliverable 3.1: Approximately how much time did you spend on this assignment?\n",
    "\n",
    "Around 3 hours or so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
